{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd1c3b8",
   "metadata": {},
   "source": [
    "2) Реализовать кернель для перемножения матрицы в bf16 на квантизованную матрицу в int4 на (X16@W4^T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e0252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({\"BLOCK_M\": 64,  \"BLOCK_N\": 64,  \"BLOCK_K\": 64},  num_warps=4, num_stages=2),\n",
    "        triton.Config({\"BLOCK_M\": 128, \"BLOCK_N\": 64,  \"BLOCK_K\": 64},  num_warps=4, num_stages=2),\n",
    "        triton.Config({\"BLOCK_M\": 64,  \"BLOCK_N\": 128, \"BLOCK_K\": 64},  num_warps=4, num_stages=2)\n",
    "    ],\n",
    "    key=[\"B\", \"IN\", \"OUT\"],\n",
    ")\n",
    "@triton.jit\n",
    "def _forward_int4_fused_kernel(x_q_ptr,\n",
    "                               w_q_ptr, w_scale_ptr,\n",
    "                               b_ptr, y_ptr,\n",
    "                               B, IN, OUT,\n",
    "                               BLOCK_M: tl.constexpr,\n",
    "                               BLOCK_N: tl.constexpr,\n",
    "                               BLOCK_K: tl.constexpr,\n",
    "                               PER_CHANNEL: tl.constexpr,\n",
    "                               HAS_BIAS: tl.constexpr):\n",
    "    pid_0 = tl.program_id(0)\n",
    "    pid_1 = tl.program_id(1)\n",
    "\n",
    "    acc = tl.full((BLOCK_M, BLOCK_N), 0.0, dtype=tl.float32)\n",
    "\n",
    "    pid_0_off = (tl.arange(0, BLOCK_M) + pid_0 * BLOCK_M) * OUT\n",
    "    pid_1_off = tl.arange(0, BLOCK_N) + pid_1 * BLOCK_N\n",
    "    off = pid_0_off[:, None] + pid_1_off[None, :]\n",
    "    \n",
    "    out_mask = ((tl.arange(0, BLOCK_M) + pid_0 * BLOCK_M) < B)[:, None] & \\\n",
    "               (pid_1_off < OUT)[None, :]  \n",
    "\n",
    "    for k in range(0, IN, BLOCK_K):\n",
    "        off_x_d0 = (tl.arange(0, BLOCK_M) + pid_0 * BLOCK_M) * IN\n",
    "        off_x_d1 = (tl.arange(0, BLOCK_K) + k)\n",
    "        off_x = off_x_d0[:, None] + off_x_d1[None, :]\n",
    "        mask_x = (off_x_d1 < IN)[None, :] & ((tl.arange(0, BLOCK_M) + pid_0 * BLOCK_M) < B)[:, None]\n",
    "\n",
    "        packed_IN = (IN + 1) // 2\n",
    "        global_cols = pid_1 * BLOCK_N + tl.arange(0, BLOCK_N)\n",
    "        out_guard = global_cols < OUT\n",
    "        safe_cols = tl.where(out_guard, global_cols, 0)\n",
    "        k_indices = tl.arange(0, BLOCK_K) + k\n",
    "        row_offsets = safe_cols[None, :] * packed_IN\n",
    "        byte_cols = (k_indices // 2)[:, None]\n",
    "        off_w = row_offsets + byte_cols\n",
    "        mask_w = (k_indices[:, None] < IN) & out_guard[None, :]\n",
    "        is_high = (k_indices & 1) == 1\n",
    "        \n",
    "\n",
    "        x = tl.load(x_q_ptr + off_x, mask_x, 0)\n",
    "        w_byte = tl.load(w_q_ptr + off_w, mask_w, 0)\n",
    "\n",
    "        w_u32 = w_byte.to(tl.uint32)\n",
    "        low = w_u32 & 0xF\n",
    "        high = (w_u32 >> 4) & 0xF\n",
    "        sel = is_high[:, None]\n",
    "        w_nib = tl.where(sel, high, low)\n",
    "        w_i32 = w_nib.to(tl.int32)\n",
    "        w_signed_i32 = tl.where(w_i32 < 8, w_i32, w_i32 - 16)\n",
    "\n",
    "        x_f16 = x.to(tl.float16)\n",
    "        w_f16 = w_signed_i32.to(tl.float16)\n",
    "        acc += tl.dot(x_f16, w_f16)\n",
    "    \n",
    "        \n",
    "\n",
    "    if PER_CHANNEL:\n",
    "        w_scale_mask = pid_1_off < OUT\n",
    "        w_scale = tl.load(w_scale_ptr + pid_1_off, mask=w_scale_mask)\n",
    "        alpha = w_scale[None, :].to(tl.float32)\n",
    "    else:\n",
    "        w_scale = tl.load(w_scale_ptr)\n",
    "        alpha = w_scale.to(tl.float32)\n",
    "\n",
    "    if HAS_BIAS:\n",
    "        bias_mask = pid_1_off < OUT\n",
    "        bias = tl.load(b_ptr + pid_1_off, mask=bias_mask, other=0).to(tl.float32)\n",
    "        acc = acc * alpha + bias[None, :]\n",
    "    else:\n",
    "        acc = acc * alpha\n",
    "\n",
    "   \n",
    "    tl.store(y_ptr + off, acc.to(tl.float16), out_mask)               \n",
    "\n",
    "def matmul_int4_fused(x: torch.Tensor,\n",
    "                      w_q: torch.Tensor,\n",
    "                      w_scale: torch.Tensor,\n",
    "                      bias: torch.Tensor | None = None,\n",
    "                      *, per_channel: bool = True) -> torch.Tensor:\n",
    "\n",
    "    B, IN = x.shape\n",
    "    OUT = w_scale.shape[0]\n",
    "\n",
    "    x_f16 = x.to(torch.float16)\n",
    "    w_scale_f16 = (w_scale.to(dtype=torch.float16, device=x.device) / 7)\n",
    "    y = torch.empty((B, OUT), dtype=torch.float16, device=x.device)\n",
    "\n",
    "    grid = lambda meta: (triton.cdiv(B, meta[\"BLOCK_M\"]),\n",
    "                     triton.cdiv(OUT, meta[\"BLOCK_N\"]))\n",
    "\n",
    "    _forward_int4_fused_kernel[grid](x_q_ptr=x_f16,\n",
    "                               w_q_ptr=w_q, w_scale_ptr=w_scale_f16,\n",
    "                               b_ptr=bias, y_ptr=y,\n",
    "                               B=B, IN=IN, OUT=OUT,\n",
    "                               PER_CHANNEL=per_channel,\n",
    "                               HAS_BIAS=(bias is not None))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a149f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/working/gate_proj_weight_0_quant.pt\"\n",
    "w_quant = torch.load(path)\n",
    "\n",
    "\n",
    "path = \"/kaggle/working/gate_proj_weight_0_quant_scale.pt\"\n",
    "w_scale = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d160adee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf04dc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_quant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52af95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512, 2048, dtype=torch.float16, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60247302",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = matmul_int4_fused(x, w_quant, w_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8273587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 8192])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3217a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6948,  1.2178, -0.1401,  ..., -0.1566, -0.9468, -0.6016],\n",
       "        [ 0.6704,  0.8579, -1.0967,  ..., -0.4187, -1.3291,  1.1094],\n",
       "        [-0.4497,  0.9160,  1.7734,  ..., -1.6924, -1.0352,  0.4187],\n",
       "        ...,\n",
       "        [ 0.7725, -0.5796,  0.0335,  ...,  1.1172, -0.6138, -0.9458],\n",
       "        [ 0.1462,  0.4265,  0.4204,  ..., -1.6094, -0.7749, -1.1484],\n",
       "        [ 0.2812,  0.2021, -0.7271,  ..., -1.3047,  0.7363,  0.1017]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0188e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/working/gate_proj_weight_0.pt\"\n",
    "w = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6a05ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c624f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d4b233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_wo_q = x @ w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fb3f15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 8192])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_wo_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b28f8e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7295,  1.3838, -0.0294,  ..., -0.3203, -0.9102, -0.4028],\n",
       "        [ 0.5757,  0.8213, -0.9316,  ..., -0.2351, -1.1084,  1.4385],\n",
       "        [-0.3137,  0.8125,  1.7363,  ..., -1.5654, -0.9619,  0.5479],\n",
       "        ...,\n",
       "        [ 0.7905, -0.5903,  0.2510,  ...,  1.0312, -1.0000, -1.0908],\n",
       "        [ 0.1451,  0.6016,  0.1072,  ..., -1.6182, -0.8105, -1.3008],\n",
       "        [ 0.1694,  0.1641, -0.8584,  ..., -1.3818,  0.6714,  0.2216]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_wo_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d29ed63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1085, device='cuda:0', dtype=torch.float16, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(res - res_wo_q).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
