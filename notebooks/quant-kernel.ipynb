{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f12d317",
   "metadata": {},
   "source": [
    "1) Реализовать кернель для квантизации 2D матрицы из fp16 в int4\n",
    "и последующей упаковки квантизованной матрицы в int8 или int32.\n",
    "При этом потребляемая память должна уменьшиться в 4 раза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57cf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({\"BLOCK_SIZE\": 1024}, num_warps=4),\n",
    "        triton.Config({\"BLOCK_SIZE\": 2048}, num_stages=1),\n",
    "    ],\n",
    "    key=[\"n_elements\"],\n",
    ")\n",
    "@triton.jit\n",
    "def _quantize_rowwise(x_ptr, output_ptr, output_maxs, n_elements, BLOCK_SIZE: tl.constexpr, P2: tl.constexpr):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * n_elements\n",
    "    row_start_ptr = x_ptr + block_start\n",
    "\n",
    "    idx = tl.arange(0, P2 // 2)\n",
    "    off_even = 2 * idx\n",
    "    off_odd = 2 * idx + 1\n",
    "\n",
    "    mask_even = off_even < n_elements\n",
    "    mask_odd = off_odd < n_elements\n",
    "\n",
    "    x_even = tl.load(row_start_ptr + off_even, mask=mask_even, other=0.0)\n",
    "    x_odd = tl.load(row_start_ptr + off_odd, mask=mask_odd, other=0.0)\n",
    "\n",
    "    absmax_even = tl.max(tl.abs(x_even))\n",
    "    absmax_odd = tl.max(tl.abs(x_odd))\n",
    "    absmax = tl.maximum(absmax_even, absmax_odd)\n",
    "\n",
    "    scale = tl.where(absmax == 0, 0.0, 7.0 / absmax)\n",
    "\n",
    "    s_even = x_even * scale\n",
    "    s_odd = x_odd * scale\n",
    "\n",
    "    q_even = tl.where(s_even >= 0, s_even + 0.5, s_even - 0.5).to(tl.int8).to(tl.uint8) & 0xF\n",
    "    q_odd = tl.where(s_odd >= 0, s_odd + 0.5, s_odd - 0.5).to(tl.int8).to(tl.uint8) & 0xF\n",
    "\n",
    "    packed = (q_odd << 4) | q_even\n",
    "\n",
    "    packed_block_start = pid * ((n_elements + 1) // 2)\n",
    "    packed_mask = idx < ((n_elements + 1) // 2)\n",
    "\n",
    "    tl.store(output_ptr + packed_block_start + idx, packed, mask=packed_mask)\n",
    "    tl.store(output_maxs + pid, absmax)\n",
    "\n",
    "\n",
    "def quantize_rowwise(x: torch.Tensor):\n",
    "    N = x.shape[0]\n",
    "    M = x.shape[1]\n",
    "\n",
    "    out_cols = (M + 1) // 2\n",
    "\n",
    "    output_tensor = torch.empty((N, out_cols), dtype=torch.uint8, device=x.device)\n",
    "\n",
    "    output_maxs = torch.empty(N, dtype=torch.float16, device=x.device)\n",
    "\n",
    "    P2 = 2 ** int(torch.ceil(torch.log2(torch.tensor(M, dtype=torch.float16))))\n",
    "\n",
    "    grid = lambda meta: (N,)\n",
    "    _quantize_rowwise[grid](x_ptr=x, output_ptr=output_tensor, output_maxs=output_maxs, n_elements=M, P2=P2)\n",
    "\n",
    "    return output_tensor, output_maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вот так вертать назад))\n",
    "v = 33\n",
    "low  = v & 0xF        # 1\n",
    "high = (v >> 4) & 0xF # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e3e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/working/gate_proj_weight_0.pt\"\n",
    "w = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefec2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc7b4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97234b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5bec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, max_ = quantize_rowwise(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86cee900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "BF16 память: 32.0\n"
     ]
    }
   ],
   "source": [
    "print(w.dtype)\n",
    "memory_bf16 = w.element_size() * w.nelement()\n",
    "print(f\"BF16 память: {memory_bf16 / 1024 ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5630c35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 2048])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a2af25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[243,  14,  47,  ..., 238,  14,  67],\n",
       "        [ 47, 224,  18,  ..., 254, 222,  14],\n",
       "        [254,  16, 241,  ...,   0,   0, 239],\n",
       "        ...,\n",
       "        [226,  14,  34,  ..., 241,  49, 252],\n",
       "        [240,  64, 192,  ...,  81,   2, 241],\n",
       "        [ 14,   1, 224,  ...,  34, 241,  31]], device='cuda:0',\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef93f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "path = \"/kaggle/working/gate_proj_weight_0_quant.pt\"\n",
    "torch.save(q, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cdfc109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 1024])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fa5828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0610, 0.0645, 0.0806,  ..., 0.0732, 0.0732, 0.0713], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f00aeabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6713a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "path = \"/kaggle/working/gate_proj_weight_0_quant_scale.pt\"\n",
    "torch.save(max_, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4e3107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "INT4 память: 8.0\n"
     ]
    }
   ],
   "source": [
    "print(q.dtype)\n",
    "memory_int4 = q.element_size() * q.nelement()\n",
    "print(f\"INT4 память: {memory_int4 / 1024 ** 2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
